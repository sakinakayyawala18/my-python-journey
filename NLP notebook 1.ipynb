{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f861691",
   "metadata": {},
   "source": [
    "hello everyone i am sakina kayyawala and we are starting our journey in nlp, lets gets started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb9a44",
   "metadata": {},
   "source": [
    "# So this notebook - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377f769",
   "metadata": {},
   "source": [
    "Q Why require nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396498b",
   "metadata": {},
   "source": [
    "Ans - To interact with computer ,and to make computer understand our basic english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4ffd2",
   "metadata": {},
   "source": [
    "before giving the text to the computer ,we have to clean the data , do some preprocessing in our text(data), that is what we gone do in todays lecture, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e2dd6",
   "metadata": {},
   "source": [
    "So we will learn preprocessing like  -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf353",
   "metadata": {},
   "source": [
    "Tokenization - sentence to word conversion for nlp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da804a",
   "metadata": {},
   "source": [
    "Stemming - base of specic word , Eg going - \"go\" here go is a base word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed539608",
   "metadata": {},
   "source": [
    "Lemmitization - base word finding out , but is should make some sense --- So base word from dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014adcd",
   "metadata": {},
   "source": [
    "stop word removal - Removing unesseray word eg remove is from \"rahul is good\", some more stopwords are to,the,he,she,this,that etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18dcf5",
   "metadata": {},
   "source": [
    "-----------From all this processing, we will get the text which will be then convert into vector , because machine understant that way ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486d2d5",
   "metadata": {},
   "source": [
    "# Lets start with the fun part (coding part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a042dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "#importing library nltk --- \"which gone a perform tasks of nlp\"\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4e15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking some story for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96069a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"The Lost Watch\n",
    "On a rainy evening, Riya dropped her old wristwatch in a busy street. She searched frantically, but it was gone. That watch wasn’t expensive, but it belonged to her late grandfather.\n",
    "Weeks later, she was buying tea from a roadside stall when she noticed something familiar on the stall owner’s wrist.\n",
    "“That’s… my watch,” she whispered.The stall owner smiled gently. “I found it on a rainy night. I was waiting for someone to claim it.”\n",
    "He handed it back without hesitation. Riya left with the watch ticking on her wrist—and her heart a little warmer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0200db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Lost Watch\\nOn a rainy evening, Riya dropped her old wristwatch in a busy street. She searched frantically, but it was gone. That watch wasn’t expensive, but it belonged to her late grandfather.\\nWeeks later, she was buying tea from a roadside stall when she noticed something familiar on the stall owner’s wrist.\\n“That’s… my watch,” she whispered.The stall owner smiled gently. “I found it on a rainy night. I was waiting for someone to claim it.”\\nHe handed it back without hesitation. Riya left with the watch ticking on her wrist—and her heart a little warmer.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7a3be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sakinakayyawala/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokenisation\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "sentence = nltk.sent_tokenize(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b51233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Lost Watch\\nOn a rainy evening, Riya dropped her old wristwatch in a busy street.',\n",
       " 'She searched frantically, but it was gone.',\n",
       " 'That watch wasn’t expensive, but it belonged to her late grandfather.',\n",
       " 'Weeks later, she was buying tea from a roadside stall when she noticed something familiar on the stall owner’s wrist.',\n",
       " '“That’s… my watch,” she whispered.The stall owner smiled gently.',\n",
       " '“I found it on a rainy night.',\n",
       " 'I was waiting for someone to claim it.”\\nHe handed it back without hesitation.',\n",
       " 'Riya left with the watch ticking on her wrist—and her heart a little warmer.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab4eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "#checking the function\n",
    "stemming.stem('going')\n",
    "stemming.stem('history') #it change the word in the base format , which can be make no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb4dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n",
      "going\n"
     ]
    }
   ],
   "source": [
    "#lematization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"history\"))\n",
    "print(lemmatizer.lemmatize(\"going\")) #it change the word in the sensibile format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea9d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lost watch rainy evening riya dropped old wristwatch busy street', 'searched frantically gone', 'watch expensive belonged late grandfather', 'week later buying tea roadside stall noticed something familiar stall owner wrist', 'watch whispered stall owner smiled gently', 'found rainy night', 'waiting someone claim handed back without hesitation', 'riya left watch ticking wrist heart little warmer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sakinakayyawala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sakinakayyawala/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK data if not done already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "corpus = []\n",
    "\n",
    "#now before performing all this things in our dataset lets just clean up our data first\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    # Remove all characters except letters (a-z and A-Z)\n",
    "    \n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentence[i])\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = review.split()\n",
    "    \n",
    "    #including lemmatizer\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ca8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lost watch rainy evening riya dropped old wristwatch busy street', 'searched frantically gone', 'watch expensive belonged late grandfather', 'week later buying tea roadside stall noticed something familiar stall owner wrist', 'watch whispered stall owner smiled gently', 'found rainy night', 'waiting someone claim handed back without hesitation', 'riya left watch ticking wrist heart little warmer', 'lost watch raini even riya drop old wristwatch busi street', 'search frantic gone', 'watch expens belong late grandfath', 'week later buy tea roadsid stall notic someth familiar stall owner wrist', 'watch whisper stall owner smile gentli', 'found raini night', 'wait someon claim hand back without hesit', 'riya left watch tick wrist heart littl warmer']\n"
     ]
    }
   ],
   "source": [
    "#same code you can perform for stemming \n",
    "for i in range(len(sentence)):\n",
    "    # Remove everything except letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentence[i])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "    \n",
    "    # Split into words\n",
    "    words = review.split()\n",
    "    \n",
    "    # Remove stopwords and stem\n",
    "    processed_words = [stemming.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    # Join back into string\n",
    "    review = ' '.join(processed_words)\n",
    "    \n",
    "    corpus.append(review)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28156603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost watch rainy evening riya dropped old wristwatch busy street\n",
      "[[0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#now last stop to make computer understand you have to change\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer (note the capital 'C' and 'V')\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the corpus and transform the text into feature vectors\n",
    "x = cv.fit_transform(corpus)\n",
    "\n",
    "# Example: print the first processed text in corpus\n",
    "print(corpus[0])\n",
    "\n",
    "# Convert the first row of the sparse matrix to a dense array and print\n",
    "print(x[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44356642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
